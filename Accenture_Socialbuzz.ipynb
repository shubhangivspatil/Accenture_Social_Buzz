{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cccb0d-614b-4e25-ba77-9fef1ee8d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "content_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\Content.csv'\n",
    "reactions_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\Reactions.csv'\n",
    "reaction_types_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\ReactionTypes.csv'\n",
    "\n",
    "# Load the datasets\n",
    "df_content = pd.read_csv(content_path)\n",
    "df_reactions = pd.read_csv(reactions_path)\n",
    "df_reaction_types = pd.read_csv(reaction_types_path)\n",
    "\n",
    "# Clean column names by stripping whitespace\n",
    "df_content.columns = df_content.columns.str.strip()\n",
    "df_reactions.columns = df_reactions.columns.str.strip()\n",
    "df_reaction_types.columns = df_reaction_types.columns.str.strip()\n",
    "\n",
    "# Clean 'Type' column values by stripping whitespace\n",
    "df_content['Type'] = df_content['Type'].str.strip()\n",
    "df_reactions['Type'] = df_reactions['Type'].str.strip()\n",
    "df_reaction_types['Type'] = df_reaction_types['Type'].str.strip()\n",
    "\n",
    "# Display cleaned column names\n",
    "print(\"Cleaned Content DataFrame columns:\")\n",
    "print(df_content.columns)\n",
    "\n",
    "print(\"\\nCleaned Reactions DataFrame columns:\")\n",
    "print(df_reactions.columns)\n",
    "\n",
    "print(\"\\nCleaned ReactionTypes DataFrame columns:\")\n",
    "print(df_reaction_types.columns)\n",
    "\n",
    "# Display unique values in 'Type' columns for each DataFrame after cleaning\n",
    "print(\"\\nCleaned Content DataFrame 'Type' column preview:\")\n",
    "print(df_content['Type'].unique())\n",
    "\n",
    "print(\"\\nCleaned Reactions DataFrame 'Type' column preview:\")\n",
    "print(df_reactions['Type'].unique())\n",
    "\n",
    "print(\"\\nCleaned ReactionTypes DataFrame 'Type' column preview:\")\n",
    "print(df_reaction_types['Type'].unique())\n",
    "\n",
    "# Merge datasets on 'Content ID'\n",
    "merged_df = pd.merge(df_content, df_reactions, on='Content ID', how='outer')\n",
    "\n",
    "# Rename 'Type_x' and 'Type_y' columns\n",
    "merged_df.rename(columns={'Type_x': 'Content_Type', 'Type_y': 'Reaction_Type'}, inplace=True)\n",
    "\n",
    "# Display merged DataFrame columns to check new names\n",
    "print(\"\\nMerged DataFrame columns after renaming:\")\n",
    "print(merged_df.columns)\n",
    "\n",
    "# Merge the result with reaction types on 'Reaction_Type'\n",
    "try:\n",
    "    final_df = pd.merge(merged_df, df_reaction_types, left_on='Reaction_Type', right_on='Type', how='left')\n",
    "except KeyError as e:\n",
    "    print(f\"\\nKeyError: {e}\")\n",
    "    print(\"\\nMerged DataFrame 'Reaction_Type' column values:\")\n",
    "    print(merged_df['Reaction_Type'].unique())\n",
    "    print(\"\\nReactionTypes DataFrame 'Type' column values:\")\n",
    "    print(df_reaction_types['Type'].unique())\n",
    "\n",
    "# Keep only the relevant columns\n",
    "final_df = final_df[['Content ID', 'Content_Type', 'Category', 'Datetime', 'Sentiment', 'Score']]\n",
    "\n",
    "# Save the final DataFrame to a new CSV file\n",
    "final_output_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\final_output.csv'\n",
    "final_df.to_csv(final_output_path, index=False)\n",
    "\n",
    "print(f\"\\nFinal merged DataFrame saved to {final_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da1f9f-c231-404d-aa24-f790f1371232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the final output DataFrame\n",
    "df_final = pd.read_csv(r'C:\\Users\\User\\Desktop\\jupiter_files\\final_output.csv')\n",
    "\n",
    "# Display initial columns and a few rows\n",
    "print(\"Initial columns and a preview:\")\n",
    "print(df_final.head())\n",
    "print(df_final.columns)\n",
    "\n",
    "# 1. Remove rows with missing values in critical columns\n",
    "# Identify critical columns based on the business questions\n",
    "critical_columns = ['Content ID', 'Content_Type', 'Category', 'Datetime', 'Sentiment', 'Score']\n",
    "df_final_clean = df_final.dropna(subset=critical_columns)\n",
    "\n",
    "# 2. Change data types\n",
    "# Convert 'Datetime' column to datetime format\n",
    "df_final_clean.loc[:, 'Datetime'] = pd.to_datetime(df_final_clean['Datetime'], errors='coerce')\n",
    "\n",
    "# Convert 'Content ID' to string (if not already)\n",
    "df_final_clean.loc[:, 'Content ID'] = df_final_clean['Content ID'].astype(str)\n",
    "\n",
    "# For 'Score', ensure it is numeric (useful for analysis)\n",
    "df_final_clean.loc[:, 'Score'] = pd.to_numeric(df_final_clean['Score'], errors='coerce')\n",
    "\n",
    "# 3. Remove irrelevant columns\n",
    "# Keep only the relevant columns\n",
    "df_final_clean = df_final_clean[['Content ID', 'Content_Type', 'Category', 'Datetime', 'Sentiment', 'Score']]\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_final_clean.to_csv(r'C:\\Users\\User\\Desktop\\jupiter_files\\final_output_cleaned.csv', index=False)\n",
    "\n",
    "# Display cleaned DataFrame columns and a preview\n",
    "print(\"\\nCleaned columns and a preview:\")\n",
    "print(df_final_clean.head())\n",
    "print(df_final_clean.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411c414-be2f-48c1-bc0b-2b26e1dbf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data\n",
    "df_clean = pd.read_csv(r'C:\\Users\\User\\Desktop\\jupiter_files\\final_output_cleaned.csv')\n",
    "\n",
    "# Group by category and sum the scores\n",
    "category_scores = df_clean.groupby('Category')['Score'].sum().reset_index()\n",
    "\n",
    "# Sort and get top 5 categories\n",
    "top_categories = category_scores.sort_values(by='Score', ascending=False).head(5)\n",
    "\n",
    "# Save the top 5 categories\n",
    "top_categories.to_csv(r'C:\\Users\\User\\Desktop\\jupiter_files\\TopCategories.csv', index=False)\n",
    "\n",
    "print(\"Top 5 categories saved to TopCategories.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebd9ad-19a4-4a20-a2c4-7e3caf643a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths\n",
    "top_categories_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\TopCategories.csv'\n",
    "final_output_cleaned_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\final_output_cleaned.csv'\n",
    "combined_excel_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\final.xlsx'\n",
    "\n",
    "# Load the CSV files into DataFrames\n",
    "df_top_categories = pd.read_csv(top_categories_path)\n",
    "df_final_clean = pd.read_csv(final_output_cleaned_path)\n",
    "\n",
    "# Save both DataFrames to an Excel file with separate sheets\n",
    "with pd.ExcelWriter(combined_excel_path, engine='openpyxl') as writer:\n",
    "    df_top_categories.to_excel(writer, sheet_name='Top Categories', index=False)\n",
    "    df_final_clean.to_excel(writer, sheet_name='Cleaned Data', index=False)\n",
    "\n",
    "print(f\"Data saved to {combined_excel_path}\")\n",
    "\n",
    "# Preview the saved Excel file\n",
    "# You can use Excel to open and check the sheets, but here's how to read it back for verification\n",
    "xls = pd.ExcelFile(combined_excel_path)\n",
    "\n",
    "# Load and preview each sheet\n",
    "df_top_categories_preview = pd.read_excel(xls, sheet_name='Top Categories')\n",
    "df_final_clean_preview = pd.read_excel(xls, sheet_name='Cleaned Data')\n",
    "\n",
    "print(\"\\nPreview of 'Top Categories' sheet:\")\n",
    "print(df_top_categories_preview.head())\n",
    "\n",
    "print(\"\\nPreview of 'Cleaned Data' sheet:\")\n",
    "print(df_final_clean_preview.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53e9db-faad-4bbe-afab-c02e123160a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset from the specified sheets\n",
    "file_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\final.xlsx'\n",
    "\n",
    "# Read the Excel file\n",
    "data_top_categories = pd.read_excel(file_path, sheet_name='Top Categories')\n",
    "data_cleaned_data = pd.read_excel(file_path, sheet_name='Cleaned Data')\n",
    "\n",
    "# Clean column names by stripping leading/trailing spaces\n",
    "data_top_categories.columns = data_top_categories.columns.str.strip()\n",
    "data_cleaned_data.columns = data_cleaned_data.columns.str.strip()\n",
    "\n",
    "# Choose the appropriate dataset for analysis\n",
    "# For this example, we'll assume you're analyzing 'Cleaned Data'\n",
    "data = data_cleaned_data\n",
    "\n",
    "# Check if the required columns exist\n",
    "required_columns = ['Category', 'Score', 'Sentiment']\n",
    "for column in required_columns:\n",
    "    if column not in data.columns:\n",
    "        raise ValueError(f\"Required column '{column}' not found.\")\n",
    "\n",
    "# Remove duplicate categories and count unique categories\n",
    "unique_categories_df = data['Category'].drop_duplicates().reset_index(drop=True)\n",
    "unique_category_count = unique_categories_df.count()\n",
    "print(f\"Number of unique categories: {unique_category_count}\")\n",
    "\n",
    "# Prepare top 5 categories by aggregate score\n",
    "top_5_categories = data.groupby('Category')['Score'].sum().sort_values(ascending=False).head(5)\n",
    "\n",
    "# Add month column if 'Datetime' is available\n",
    "if 'Datetime' in data.columns:\n",
    "    data['Datetime'] = pd.to_datetime(data['Datetime'], errors='coerce')\n",
    "    data['Month'] = data['Datetime'].dt.to_period('M')\n",
    "\n",
    "    # Aggregate scores by category and month\n",
    "    monthly_scores = data.groupby(['Category', 'Month'])['Score'].sum().unstack().fillna(0)\n",
    "\n",
    "    # Heatmap for aggregate scores by category and month\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(monthly_scores, cmap='viridis', annot=True, fmt=\".1f\", linewidths=0.5, linecolor='gray')\n",
    "    plt.title('Aggregate Scores by Category and Month')\n",
    "    plt.tight_layout()\n",
    "    heatmap_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\heatmap_aggregate_scores.png'\n",
    "    plt.savefig(heatmap_path)\n",
    "    plt.show()\n",
    "\n",
    "# Bar graph for unique categories count\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=['Unique Categories'], y=[unique_category_count], palette='coolwarm')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Unique Categories')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "bar_chart_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\unique_categories_bar_graph.png'\n",
    "plt.savefig(bar_chart_path)\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for top 5 categories by aggregate score\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(top_5_categories, labels=top_5_categories.index, autopct='%1.1f%%', startangle=140, \n",
    "        colors=sns.color_palette('plasma', len(top_5_categories)), wedgeprops=dict(width=0.4, edgecolor='w'))\n",
    "plt.title('Top 5 Categories by Aggregate \"Popularity\" Score')\n",
    "plt.tight_layout()\n",
    "pie_chart_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\top_5_categories_pie_chart.png'\n",
    "plt.savefig(pie_chart_path)\n",
    "plt.show()\n",
    "\n",
    "# Bar chart for sentiment distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sentiment_counts = data['Sentiment'].value_counts()\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette='coolwarm')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution')\n",
    "for i, count in enumerate(sentiment_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "sentiment_chart_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\sentiment_distribution_bar_chart.png'\n",
    "plt.savefig(sentiment_chart_path)\n",
    "plt.show()\n",
    "\n",
    "# Bar chart for category distribution\n",
    "plt.figure(figsize=(12, 8))\n",
    "category_counts = data['Category'].value_counts()\n",
    "sns.barplot(x=category_counts.index, y=category_counts.values, palette='magma')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Category Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "for i, count in enumerate(category_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "category_chart_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\category_distribution_bar_chart.png'\n",
    "plt.savefig(category_chart_path)\n",
    "plt.show()\n",
    "\n",
    "# Most popular category based on the number of posts\n",
    "most_popular_category = data['Category'].value_counts().idxmax()\n",
    "print(f\"Most popular category: {most_popular_category}\")\n",
    "\n",
    "# Count of reactions to the most popular category\n",
    "reactions_to_most_popular = data[data['Category'] == most_popular_category].shape[0]\n",
    "print(f\"Reactions to the most popular category: {reactions_to_most_popular}\")\n",
    "\n",
    "# Key Insights\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"1. Number of unique categories: {unique_category_count}\")\n",
    "print(f\"2. Most popular category: {most_popular_category}\")\n",
    "print(f\"3. Count of reactions to the most popular category: {reactions_to_most_popular}\")\n",
    "print(f\"4. Top 5 categories by aggregate score:\\n{top_5_categories}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33867ae-cca3-44cf-9c0c-e2c7c4a507c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-pptx Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70167899-8969-4956-8d0e-061cd61613a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from PIL import Image\n",
    "\n",
    "# Create a presentation object\n",
    "prs = Presentation()\n",
    "\n",
    "# Paths to the saved charts\n",
    "chart_paths = {\n",
    "    \"Unique Categories Bar Graph\": r'C:\\Users\\User\\Desktop\\jupiter_files\\unique_categories_bar_graph.png',\n",
    "    \"Top 5 Categories Pie Chart\": r'C:\\Users\\User\\Desktop\\jupiter_files\\top_5_categories_pie_chart.png',\n",
    "    \"Sentiment Distribution Bar Chart\": r'C:\\Users\\User\\Desktop\\jupiter_files\\sentiment_distribution_bar_chart.png',\n",
    "    \"Category Distribution Bar Chart\": r'C:\\Users\\User\\Desktop\\jupiter_files\\category_distribution_bar_chart.png',\n",
    "    \"Heatmap of Aggregate Scores\": r'C:\\Users\\User\\Desktop\\jupiter_files\\heatmap_aggregate_scores.png'\n",
    "}\n",
    "\n",
    "# Add a title slide\n",
    "slide_title = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "title = slide_title.shapes.title\n",
    "subtitle = slide_title.placeholders[1]\n",
    "title.text = \"Exploratory Data Analysis\"\n",
    "subtitle.text = \"Key Visualizations and Insights\"\n",
    "\n",
    "# Function to add a slide with a chart image\n",
    "def add_chart_slide(prs, title_text, image_path):\n",
    "    slide_layout = prs.slide_layouts[5]\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    title.text = title_text\n",
    "    left = top = Inches(1)\n",
    "    pic = slide.shapes.add_picture(image_path, left, top, width=Inches(8), height=Inches(5))\n",
    "\n",
    "# Add slides for each chart\n",
    "for title, path in chart_paths.items():\n",
    "    add_chart_slide(prs, title, path)\n",
    "\n",
    "# Add a slide for key insights\n",
    "slide_insights = prs.slides.add_slide(prs.slide_layouts[1])\n",
    "title = slide_insights.shapes.title\n",
    "title.text = \"Key Insights\"\n",
    "\n",
    "# Add text box for insights\n",
    "insights_content = (\n",
    "    \"1. Number of unique categories: [Insert Number Here]\\n\"\n",
    "    \"2. Most popular category: [Insert Category Here]\\n\"\n",
    "    \"3. Count of reactions to the most popular category: [Insert Count Here]\\n\"\n",
    "    \"4. Top 5 categories by aggregate score:\\n\"\n",
    "    \"[Insert Top 5 Categories Here]\"\n",
    ")\n",
    "\n",
    "# Define the position and size of the text box\n",
    "left = Inches(1)\n",
    "top = Inches(1.5)\n",
    "width = Inches(8)\n",
    "height = Inches(4.5)\n",
    "\n",
    "text_box = slide_insights.shapes.add_textbox(left, top, width, height)\n",
    "text_frame = text_box.text_frame\n",
    "p = text_frame.add_paragraph()\n",
    "p.text = insights_content\n",
    "p.space_after = Inches(0.1)\n",
    "\n",
    "# Save the presentation\n",
    "pptx_file_path = r'C:\\Users\\User\\Desktop\\jupiter_files\\EDA_Presentation.pptx'\n",
    "prs.save(pptx_file_path)\n",
    "\n",
    "print(f\"Presentation saved at {pptx_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc53dce-69e7-4026-b8b5-adbc66930503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
